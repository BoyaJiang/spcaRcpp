% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/spcaRcpp.R
\name{spcaRcpp}
\alias{spcaRcpp}
\title{Rcpp Integration for Sparse Principal Component Analysis (spca).}
\usage{
spcaRcpp(
  X,
  k = NULL,
  alpha = 1e-04,
  beta = 1e-04,
  center = TRUE,
  max_iter = 1000,
  tol = 1e-05
)
}
\arguments{
\item{X}{a numeric matrix or data.frame which provides the data for 
the sparse principal components analysis.}

\item{k}{optional, a number specifying the maximal rank.}

\item{alpha}{Sparsity controlling parameter. Higher values means sparser components.}

\item{beta}{Amount of ridge shrinkage to apply in order to improve conditioning.}

\item{center}{a logical value indicating whether the variables should be 
shifted to be zero centered.}

\item{max_iter}{maximum number of iterations to perform.}

\item{tol}{stopping criteria for the convergence.}
}
\value{
\code{spcaRcpp} returns a list containing the following six components:
\item{loadings}{  the matrix of variable loadings. 
}

\item{standard deviations}{  the approximated standard deviations.
}

\item{eigenvalues}{  the approximated eigenvalues.
}

\item{center}{  the centering used.
}

\item{var}{  the variance.
}

\item{scores}{  the principal component scores.
}
}
\description{
Implementation of SPCA, using variable projection as an optimization strategy.
}
\details{
Sparse principal component analysis is a specialized variant of PCA. Specifically, SPCA promotes sparsity
in the modes, i.e., the sparse modes have only a few active (nonzero) coefficients, while the majority of coefficients
are constrained to be zero. This approach leads to a improved localization and interpretability of the model
compared to the global PCA modes obtained from traditional PCA. In addition, SPCA avoids overfitting in a 
high-dimensional data setting where the number of variables \eqn{p} is greater than the number of
observations \eqn{n}.  

Given an \eqn{(n,p)} data matrix \eqn{X}, SPCA attemps to minimize the following
objective function:

minimize f(A,B) = 1/2⋅‖X - X⋅B⋅Aᵀ‖² + α⋅‖B‖₁ + 1/2⋅β‖B‖², subject to AᵀA = I.

where \eqn{B} is the sparse weight matrix and \eqn{A} is an orthonormal matrix.
The principal components \eqn{Z} are formed as

\deqn{ Z = X B }{Z = X * B}

and the data can be approximately rotated back as

\deqn{ \tilde{X} = Z A^\top }{ X = Z t(A)}

The print method can be used to present the results in a nice format.
}
\examples{

# Create artifical data
m <- 10000
V1 <- rnorm(m, -100, 200)
V2 <- rnorm(m, -100, 300)
V3 <- -0.1 * V1 + 0.1 * V2 + rnorm(m, 0, 100)

X <- cbind(V1, V1, V1, V1, V2, V2, V2, V2, V3, V3)
X <- X + matrix( rnorm( length(X), 0, 1 ), ncol = ncol(X), nrow = nrow(X) )

# Compute SPCA
out <- spcaRcpp(X, k=3, alpha=1e-4, beta=1e-4, center = TRUE)
print(out)


}
\references{
\itemize{

 \item [1] N. B. Erichson, P. Zheng, K. Manohar, S. Brunton, J. N. Kutz, A. Y. Aravkin.
 "Sparse Principal Component Analysis via Variable Projection."
 SIAM Journal on Applied Mathematics 2020 80:2, 977-1002
 (available at `arXiv \url{https://arxiv.org/abs/1804.00341}).


\item [2] N. B. Erichson, P. Zheng, S. Aravkin, sparsepca, (2018), GitHub repository,
\url{https://github.com/erichson/spca}. 
}
}
\author{
Boya Jiang
}
